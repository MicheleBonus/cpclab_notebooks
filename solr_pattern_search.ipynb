{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8JXNmc3vLQ2u8COTb0t39",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicheleBonus/cpclab_notebooks/blob/main/solr_pattern_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7mfb4SLFZsP3"
      },
      "outputs": [],
      "source": [
        "# @title Run the following code cell first\n",
        "import datetime\n",
        "import requests\n",
        "import pandas as pd\n",
        "!pip install solrq\n",
        "from solrq import Q\n",
        "from copy import deepcopy\n",
        "\n",
        "class PDBESearch:\n",
        "    BASE_URL = \"https://www.ebi.ac.uk/pdbe/search/pdb/select?\"\n",
        "\n",
        "    def __init__(self, search_pattern):\n",
        "        self.search_pattern = search_pattern\n",
        "        self.search_terms_status = Q(status='REL')\n",
        "        self._set_search_terms()\n",
        "\n",
        "        self.filter_terms = [\n",
        "            'pdb_id', 'number_of_polymer_entities', 'number_of_polymers', 'number_of_bound_entities',\n",
        "            'number_of_bound_molecules', 'experimental_method', 'release_year', 'resolution', 'ec_number',\n",
        "            'has_bound_molecule', 'bound_compound_id', 'em_resolution', 'data_quality', 'assembly_mol_wt',\n",
        "            'journal', 'refinement_software', 'synchrotron_site', 'em_electron_detection',\n",
        "            'cath_homologous_superfamily', 'assembly_composition', 'processing_site'\n",
        "        ]\n",
        "\n",
        "    def _set_search_terms(self):\n",
        "        self.search_terms_regex = f\"molecule_sequence:/{self.search_pattern}/\"\n",
        "        self.full_search_terms = str(self.search_terms_status) + \" AND \" + self.search_terms_regex\n",
        "\n",
        "    @staticmethod\n",
        "    def _change_lists_to_strings(results):\n",
        "        for row in results:\n",
        "            for data in row:\n",
        "                if type(row[data]) == list:\n",
        "                    row[data] = [str(a) for a in row[data]]\n",
        "                    row[data] = ','.join(sorted(list(set(row[data]))))\n",
        "        return results\n",
        "\n",
        "    def fetch_data(self):\n",
        "        search_params = {\n",
        "            'q': self.full_search_terms,\n",
        "            'fl': ','.join(self.filter_terms),\n",
        "            'rows': 100,\n",
        "            'wt': 'json',\n",
        "            'group': 'true',\n",
        "            'group.field': 'pdb_id',\n",
        "            'group.ngroups': 'true'\n",
        "        }\n",
        "\n",
        "        response = requests.post(self.BASE_URL, data=search_params)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            response_data = response.json()\n",
        "            preresults = response_data.get('grouped', {}).get('pdb_id', {}).get('groups', [])\n",
        "\n",
        "            all_results = []\n",
        "            for group in preresults:\n",
        "                docs = group.get('doclist', {}).get('docs', [])\n",
        "                all_results.extend(docs)\n",
        "\n",
        "            all_results_copy = deepcopy(all_results)\n",
        "            all_results_cleaned = self._change_lists_to_strings(all_results_copy)\n",
        "            all_results_cleaned_df = pd.DataFrame(all_results_cleaned)\n",
        "            return all_results_cleaned_df\n",
        "        else:\n",
        "            raise Exception(f\"[No data retrieved - {response.status_code}] {response.text}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set parameters and run code cell\n",
        "Either run the example or change the regular expression. Examples for valid regular expressions are:\n",
        "- `'.*?G.{4}GK[TS].*'` (*anything* -- **G** -- *any 4 amino acids* -- **GK** -- *either* **T** *or* **S** -- *anything*)\n",
        "- `'.*?[RK].{2,3}[DE].{2,3}Y.*'` (*anything* -- *either* **R** *or* **K** -- *any 2 or 3 amino acids* -- *either* **D** *or* **E** -- *any 2 or 3 amino acids* -- **Y** -- *anything*)"
      ],
      "metadata": {
        "id": "KKP7Cj9saEnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = '.*?G.{4}GK[TS].*'\n",
        "searcher = PDBESearch(search_pattern=pattern)\n",
        "df = searcher.fetch_data()\n",
        "df"
      ],
      "metadata": {
        "id": "9nlWKGDbZwV1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Remarks\n",
        "## 1. Limited results\n",
        "For demonstration purposes, we will only search until we received 100 results. This is defined in the code at:\n",
        "\n",
        "```python\n",
        "...\n",
        "    def fetch_data(self):\n",
        "        search_params = {\n",
        "            'q': self.full_search_terms,\n",
        "            'fl': ','.join(self.filter_terms),\n",
        "            'rows': 100,\n",
        "            'wt': 'json',\n",
        "            'group': 'true',\n",
        "            'group.field': 'pdb_id',\n",
        "            'group.ngroups': 'true'\n",
        "        }\n",
        "...\n",
        "```\n",
        "\n",
        "If you want to return all data, you might want to change this to `220000` (a number that is slightly above the total number of structures in the PDB.\n",
        "\n",
        "## 2. Custom output\n",
        "Whatever is in the final dataframe is fully customizable. This is defined in the code at:\n",
        "\n",
        "```python\n",
        "...\n",
        "        self.filter_terms = [\n",
        "            'pdb_id', 'number_of_polymer_entities', 'number_of_polymers', 'number_of_bound_entities',\n",
        "            'number_of_bound_molecules', 'experimental_method', 'release_year', 'resolution', 'ec_number',\n",
        "            'has_bound_molecule', 'bound_compound_id', 'em_resolution', 'data_quality', 'assembly_mol_wt',\n",
        "            'journal', 'refinement_software', 'synchrotron_site', 'em_electron_detection',\n",
        "            'cath_homologous_superfamily', 'assembly_composition', 'processing_site'\n",
        "        ]\n",
        "...\n",
        "```"
      ],
      "metadata": {
        "id": "I1VcTsarci07"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Qe7YFsBcrnh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}